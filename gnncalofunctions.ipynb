{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "407a0075-1c5f-4028-91a2-a089201ccd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split\n",
    "from collections import namedtuple, defaultdict\n",
    "import random\n",
    "random.seed(42)\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from torchvision import transforms\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import joblib # efficiently serializes python objects and is used in saving and loading machine learning models\n",
    "import json # encode/decode JSON data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af61e3ca-46a0-4950-a0f9-44d74ea6ca76",
   "metadata": {},
   "source": [
    "## Methods for the pairing datapoints notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcd7c917-159d-4720-845e-f4714b4c0b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def branches_from_root_file(filename):\n",
    "    '''\n",
    "    Returns the branches from a root file\n",
    "    '''\n",
    "    file = uproot.open(filename)\n",
    "    tree = file[file.keys()[0]]\n",
    "    branches = tree.arrays()\n",
    "    return branches\n",
    "\n",
    "# Original Code:\n",
    "# file = uproot.open(\"MyxAODAnalysis_all2D.outputs.root\")\n",
    "# file.keys()\n",
    "# tree = file['analysis']\n",
    "# branches = tree.arrays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88079dc6-da2c-4564-a867-1f1fdc13cb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables = [cell_coordinate_x, cell_coordinate_y, cell_coordinate_z, cell_eta, cell_phi, cell_sampling, cell_noiseSigma, cell_e]\n",
    "# generalized_range = len(cell_to_cluster_index)\n",
    "\n",
    "def create_data_dict(range_value, variables):\n",
    "    for i in range(generalized_range):\n",
    "        data[f\"data_{i}\"] = np.concatenate([np.expand_dims(var[i], axis=1) for var in variables], axis=1)\n",
    "    return data\n",
    "    \n",
    "# Original Code:\n",
    "# data = {}\n",
    "# for i in range(generalized_range):\n",
    "#     data[f\"data_{i}\"] = np.concatenate((np.expand_dims(cell_coordinate_x[i], axis=1), np.expand_dims(cell_coordinate_y[i], axis=1), np.expand_dims(cell_coordinate_z[i], axis=1),\n",
    "#                         np.expand_dims(cell_eta[i], axis=1), np.expand_dims(cell_phi[i], axis=1),\n",
    "#                         np.expand_dims(cell_sampling[i], axis=1),\n",
    "#                         np.expand_dims(cell_noiseSigma[i], axis=1),\n",
    "#                         np.expand_dims(cell_e[i], axis=1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a01178d-6b6f-4dc7-8cf5-e6e2a5f45e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict_to_hdf5(dic, filename):\n",
    "    \"\"\"Save a dictionary to an HDF5 file\"\"\"\n",
    "    with h5py.File(filename, 'w') as f:\n",
    "        _save_dict_to_hdf5(f, dic)\n",
    "# Opens hdf5 file in write mode. Calls a helper function\n",
    "# to recursively save the dictionary to the hdf5 file.\n",
    "\n",
    "def _save_dict_to_hdf5(group, dic):\n",
    "    \"\"\"Save a dictionary to an HDF5 group\"\"\"\n",
    "    for key, value in dic.items():\n",
    "        if isinstance(value, dict):\n",
    "            subgroup = group.create_group(key)\n",
    "            _save_dict_to_hdf5(subgroup, value)\n",
    "        else:\n",
    "            if isinstance(value, list):\n",
    "                \"\"\"Convert list to numpy array before saving\"\"\"\n",
    "                value = np.array(value)\n",
    "            group[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06ee63b-c08c-4f64-ba5d-18d63b64faf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A code to remove permutation variant\n",
    "def canonical_form(t):\n",
    "    \"\"\"Sorts elements of the tuple and converts the sorted list back into a tuple.\"\"\"\n",
    "    return tuple(sorted(t))\n",
    "\n",
    "def remove_permutation_variants(tuple_list):\n",
    "    \"\"\"\n",
    "    Creates a set of unique tuples by converting each tuple to its canonical form.\n",
    "    Remove permutation variants from a list of tuples.\n",
    "    Converts set back into a list of tuples.\n",
    "    \"\"\"\n",
    "    unique_tuples = set(canonical_form(t) for t in tuple_list)\n",
    "    return [tuple(sorted(t)) for t in unique_tuples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7df4382-0065-4a07-95d4-93ad63c95d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lone_bkg_neighbor_clusters_labels():\n",
    "    print(\"Label for True: 1\")\n",
    "    print(\"Label for Lone-Lone: 0\")\n",
    "    print(\"Label for Cluster-Lone: 2\")\n",
    "    print(\"Label for Cluster-Cluster: 3\")\n",
    "    for pair in neighbor_pairs_unique_sorted:\n",
    "        if cell_to_cluster_index[i][pair[0]] == cell_to_cluster_index[i][pair[1]]:\n",
    "        # Both cells in the pair belong to the same cluster\n",
    "            if cell_to_cluster_index[i][pair[0]] != 0:\n",
    "                true_neighbor_cluster_event.append(1)  # Cluster-Cluster (True)\n",
    "            else:\n",
    "                true_neighbor_cluster_event.append(0)  # Lone-Lone\n",
    "        else:\n",
    "            if cell_to_cluster_index[i][pair[0]] != 0 and cell_to_cluster_index[i][pair[1]] != 0:\n",
    "                true_neighbor_cluster_event.append(3)  # Cluster-Cluster\n",
    "            else:\n",
    "                true_neighbor_cluster_event.append(2)  # Cluster-Lone\n",
    "\n",
    "def cluster_lone_bkg_neighbor_clusters_labels():\n",
    "    print(\"Label for True: 1\")\n",
    "    print(\"Label for Lone-Lone: 2\")\n",
    "    print(\"Label for Cluster-Lone: 0\")\n",
    "    print(\"Label for Cluster-Cluster: 3\")\n",
    "    for pair in neighbor_pairs_unique_sorted:\n",
    "        if cell_to_cluster_index[i][pair[0]] == cell_to_cluster_index[i][pair[1]]:\n",
    "        # Both cells in the pair belong to the same cluster\n",
    "            if cell_to_cluster_index[i][pair[0]] != 0:\n",
    "                true_neighbor_cluster_event.append(1)  # Cluster-Cluster (True)\n",
    "            else:\n",
    "                true_neighbor_cluster_event.append(2)  # Lone-Lone\n",
    "        else:\n",
    "            if cell_to_cluster_index[i][pair[0]] != 0 and cell_to_cluster_index[i][pair[1]] != 0:\n",
    "                true_neighbor_cluster_event.append(3)  # Cluster-Cluster\n",
    "            else:\n",
    "                true_neighbor_cluster_event.append(0)  # Cluster-Lone\n",
    "\n",
    "def cluster_cluster_bkg_neighbor_clusters_labels():\n",
    "    print(\"Label for True: 1\")\n",
    "    print(\"Label for Lone-Lone: 3\")\n",
    "    print(\"Label for Cluster-Lone: 2\")\n",
    "    print(\"Label for Cluster-Cluster: 0\")\n",
    "    for pair in neighbor_pairs_unique_sorted:\n",
    "        if cell_to_cluster_index[i][pair[0]] == cell_to_cluster_index[i][pair[1]]:\n",
    "        # Both cells in the pair belong to the same cluster\n",
    "            if cell_to_cluster_index[i][pair[0]] != 0:\n",
    "                true_neighbor_cluster_event.append(1)  # Cluster-Cluster (True)\n",
    "            else:\n",
    "                true_neighbor_cluster_event.append(3)  # Lone-Lone\n",
    "        else:\n",
    "            if cell_to_cluster_index[i][pair[0]] != 0 and cell_to_cluster_index[i][pair[1]] != 0:\n",
    "                true_neighbor_cluster_event.append(0)  # Cluster-Cluster\n",
    "            else:\n",
    "                true_neighbor_cluster_event.append(2)  # Cluster-Lone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffd2dd6d-4dc8-4f38-89c7-622c3fb414e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_neighbor_clusters(cell_to_cluster_index, neighbor_pairs_unique_sorted, background_setting):\n",
    "    true_neighbor_cluster = []\n",
    "\n",
    "    for i in range(len(cell_to_cluster_index)):\n",
    "        true_neighbor_cluster_event = []\n",
    "        # Append zero value based on the background setting\n",
    "        if background_setting == 'lone':\n",
    "            lone_bkg_neighbor_clusters_labels()\n",
    "        elif background_setting == 'cluster-lone':\n",
    "            cluster_lone_bkg_neighbor_clusters_labels()\n",
    "        elif background_setting == 'cluster-cluster':\n",
    "            cluster_cluster_bkg_neighbor_clusters_labels()       \n",
    "    return true_neighbor_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb2ba7-f130-4f44-8d5a-59b8ce6bce98",
   "metadata": {},
   "source": [
    "## Methods for the data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a62cbd66-96e6-49d9-82e4-0754869008fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hdf5_to_dict(hdf5_file):\n",
    "    \"\"\"\n",
    "    Convert HDF5 file to Python dictionary\n",
    "    \"\"\"\n",
    "    data_dict = {}\n",
    "    _hdf5_to_dict(hdf5_file, data_dict)\n",
    "    return data_dict\n",
    "# Initializes an empty dictionary and calls a function to recursively\n",
    "# fill this dictionary with data from the hdf5 file.\n",
    "\n",
    "\n",
    "def _hdf5_to_dict(group, dic):\n",
    "    \"\"\"\n",
    "    Convert HDF5 group to dictionary recursively\n",
    "    \"\"\"\n",
    "    for key, item in group.items():\n",
    "        if isinstance(item, h5py.Group):\n",
    "            subgroup = {}\n",
    "            _hdf5_to_dict(item, subgroup)\n",
    "            dic[key] = subgroup\n",
    "        else:\n",
    "            dic[key] = np.array(item)\n",
    "# Iterates over items in the hdf5 group. If the item is a group, \n",
    "# it creates a new dictionary and calls itself recursively. If the item\n",
    "# is a dataset, it converts it to a numpy array and stores it in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10bd6d64-b0f8-40d0-aebe-2021325adee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicies_of_edges(range_value, true_list, bkg_0, bkg_2, bkg_3):\n",
    "    '''\n",
    "    bkg_0 represents the background with a truth value of 0\n",
    "    bkg_2/3 represents the background with a truth value of 2/3\n",
    "    '''\n",
    "    for i in range(range_value):\n",
    "        true_list.append(list(np.where(neigbor_truth_100evs[i]==1)[0]))\n",
    "        bkg_0.append(list(np.where(neigbor_truth_100evs[i]==0)[0]))\n",
    "        bkg_2.append(list(np.where(neigbor_truth_100evs[i]==2)[0]))\n",
    "        bkg_3.append(list(np.where(neigbor_truth_100evs[i]==3)[0]))\n",
    "    return np.array(true_list), np.array(bkg_0), np.array(bkg_2), np.array(bkg_3)\n",
    "\n",
    "def pairs_of_edges(range_value, true_list, bkg_0, bkg_2, bkg_3):\n",
    "    '''\n",
    "    bkg_0 represents the background with a truth value of 0\n",
    "    bkg_2/3 represents the background with a truth value of 2/3\n",
    "    '''\n",
    "    for i in range(range_value):\n",
    "        true_list.append(len(true[i]))\n",
    "        bkg_0.append(len(bkg_0[i]))\n",
    "        bkg_2.append(len(bkg_2[i]))\n",
    "        bkg_3.append(len(bkg_3[i]))\n",
    "    return np.array(true_list), np.array(bkg_0), np.array(bkg_2), np.array(bkg_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "646d1587-e006-4655-ba5f-675793a867dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting_indicies(pair_number_list, true_list, bkg_0, bkg_2, bkg_3):\n",
    "    sorted_indices = np.argsort(-pair_number_list)\n",
    "    return true_list[sorted_indices], bkg_0[sorted_indices], bkg_2[sorted_indices], bkg_3[sorted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db713174-5683-4c5c-be7e-7cd6617dc4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_set_test_set(split_num, true_list, bkg_0, bkg_2, bkg_3):\n",
    "    return true_list[:split_num],bkg_0[:split_num],bkg_2[:split_num],bkg_3[:split_num], true_list[split_num:],bkg_0[split_num:],bkg_2[split_num:],bkg_3[split_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e52e36e7-f17f-4df9-b568-6906e7d0c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_of_features(dynamic_variables, split_num, sorted_indicies):\n",
    "    keys = list(dynamic_variables.keys())\n",
    "    values = list(dynamic_variables.values())\n",
    "    #Gets the keys and variables from the dynamic variables array and stores them in arrays.\n",
    "    \n",
    "    rearranged_values = [values[i] for i in sorted_indicies]\n",
    "    #Sorts the values with the sorted cluster indices.\n",
    "    \n",
    "    rearranged_dict = dict(zip(keys, rearranged_values))\n",
    "    #Creates a rearranged dictionary out of the keys and sorted values.\n",
    "    \n",
    "    data_train = np.concatenate([value for key, value in list(rearranged_dict.items())[:split_num]])\n",
    "    #Create a training data array.\n",
    "    \n",
    "    data_test = np.concatenate([value for key, value in list(dynamic_variables.items())[split_num:]])\n",
    "    #Create a data testing array.\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    cellFeatures_trainS = scaler.fit_transform(data_train)\n",
    "    scaler_filename = \"./bscaler_neighbor_data_train_sorted.save\"\n",
    "    joblib.dump(scaler, scaler_filename)\n",
    "    #Scales the training data with a minmaxscaler, put that scaled data into a training features array, and then save that scaler into a .save file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35549638-1260-4483-8306-dcf83153cb1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
